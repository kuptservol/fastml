{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from fastml.core import *\n",
    "from fastml.data.datasets import *\n",
    "from fastml.model import loss as loss\n",
    "from fastml.model import metrics as metrics\n",
    "from fastml.model import optimizers\n",
    "from fastml.model.callbacks import *\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, n_in, nh, n_out):\n",
    "        super().__init__()\n",
    "        self.layers = [nn.Linear(n_in,nh), nn.ReLU(), nn.Linear(nh,n_out)]\n",
    "        self.loss = loss.mse\n",
    "        \n",
    "    def __call__(self, x, targ):\n",
    "        for layer in self.layers: x = layer(x)\n",
    "        return self.loss(x.squeeze(), targ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds,valid_ds = Datasets.MNIST()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50000, 784])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(784, 50, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, n_in, nh, n_out):\n",
    "        super().__init__()\n",
    "        self.l1 = nn.Linear(n_in, nh)\n",
    "        self.l2 = nn.Linear(nh, n_out)\n",
    "\n",
    "    def __call__(self, x): return self.l2(F.relu(self.l1(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name,l in model.named_children(): print(f\"{name}: {l}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0.3411, -0.1001, -0.1526, -0.1610,  0.0275,  0.3288, -0.1032,  0.2343,\n",
       "          0.1038,  0.4645], grad_fn=<SelectBackward>), torch.Size([64, 10]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs=64 # batch size\n",
    "\n",
    "model = Model(784, 50, 10)\n",
    "xb, yb = train_ds[0:bs] # a mini-batch from x\n",
    "preds = model(xb)      # predictions\n",
    "\n",
    "preds[0], preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = metrics.accuracy(preds, yb[0:bs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## basic train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = train_ds.x, train_ds.y\n",
    "x_valid, y_valid = valid_ds.x, valid_ds.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.5\n",
    "epochs = 2\n",
    "batch_size=64\n",
    "loss_func = loss.cross_entropy()\n",
    "model = Model(784, 50, 10)\n",
    "\n",
    "def fit():\n",
    "    for epoch in range(epochs):\n",
    "        for batch in range(x_train.shape[0]//batch_size):\n",
    "            \n",
    "            b_from = batch*batch_size\n",
    "            b_to = b_from + batch_size\n",
    "            x_batch, y_batch = train_ds[b_from:b_to]\n",
    "            \n",
    "            loss = loss_func(model(x_batch), y_batch)\n",
    "            \n",
    "            loss.backward()\n",
    "            with torch.no_grad():\n",
    "                for p in model.parameters(): p -= lr * p.grad\n",
    "                model.zero_grad()\n",
    "            \n",
    "        accuracy = metrics.accuracy(model(x_train), y_train)\n",
    "        print(\"epoch %s accuracy is %f3\" % (epoch, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assert_train_accuracy():\n",
    "    assert metrics.accuracy(model(x_train), y_train) > 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 accuracy is 88.6139993\n",
      "epoch 1 accuracy is 91.1400023\n"
     ]
    }
   ],
   "source": [
    "fit()\n",
    "assert_train_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequentialModel(nn.Module):\n",
    "    def __init__(self, layers):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList(layers)\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        for l in self.layers: x = l(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 accuracy is 88.6160023\n",
      "epoch 1 accuracy is 92.0639993\n"
     ]
    }
   ],
   "source": [
    "layers = [nn.Linear(784,50), nn.ReLU(), nn.Linear(50,10)]\n",
    "model = SequentialModel(layers)\n",
    "\n",
    "fit()\n",
    "assert_train_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 accuracy is 90.7700003\n",
      "epoch 1 accuracy is 92.8460003\n"
     ]
    }
   ],
   "source": [
    "model = nn.Sequential(nn.Linear(784,50), nn.ReLU(), nn.Linear(50,10))\n",
    "\n",
    "fit()\n",
    "assert_train_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=784, out_features=50, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=50, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    return nn.Sequential(nn.Linear(784,50), nn.ReLU(), nn.Linear(50,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 accuracy is 85.4900003\n",
      "epoch 1 accuracy is 91.6199983\n"
     ]
    }
   ],
   "source": [
    "model = create_model()\n",
    "\n",
    "fit()\n",
    "assert_train_accuracy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## with optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model()\n",
    "optimizer = optimizers.SGD(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit():\n",
    "    for epoch in range(epochs):\n",
    "        for batch in range(x_train.shape[0]//batch_size):\n",
    "            \n",
    "            b_from = batch*batch_size\n",
    "            b_to = b_from + batch_size\n",
    "            x_batch, y_batch = train_ds[b_from:b_to]\n",
    "            \n",
    "            loss = loss_func(model(x_batch), y_batch)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "        accuracy = metrics.accuracy(model(x_train), y_train)\n",
    "        print(\"epoch %s accuracy is %f3\" % (epoch, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 accuracy is 91.4359993\n",
      "epoch 1 accuracy is 92.2940023\n"
     ]
    }
   ],
   "source": [
    "fit()\n",
    "assert_train_accuracy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## with data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl,_ = get_data_loaders(train_ds, valid_ds, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model()\n",
    "optimizer = optimizers.SGD(model)\n",
    "\n",
    "def fit():\n",
    "    for epoch in range(epochs):\n",
    "        for x_batch, y_batch in train_dl:\n",
    "            \n",
    "            loss = loss_func(model(x_batch), y_batch)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "        accuracy = metrics.accuracy(model(x_train), y_train)\n",
    "        print(\"epoch %s accuracy is %f3\" % (epoch, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 accuracy is 95.1179983\n",
      "epoch 1 accuracy is 93.8160003\n"
     ]
    }
   ],
   "source": [
    "fit()\n",
    "assert_train_accuracy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## with validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assert_valid_accuracy():\n",
    "    assert metrics.accuracy(model(x_valid), y_valid) > 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(epochs, model, train_dl, valid_dl, optimizer, loss_func):\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        # set model to train_mode\n",
    "        model.train()\n",
    "        \n",
    "        for x_batch, y_batch in train_dl:\n",
    "        \n",
    "            loss = loss_func(model(x_batch), y_batch)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "        # set model to eval_mode\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            total_accuracy, total_loss = 0., 0.\n",
    "            for x_valid_batch, y_valid_batch in valid_dl:\n",
    "                valid_preds = model(x_valid_batch)\n",
    "                total_loss+=loss_func(valid_preds, y_valid_batch)\n",
    "                total_accuracy+=metrics.accuracy(valid_preds, y_valid_batch)\n",
    "                \n",
    "        n = len(valid_dl)        \n",
    "        print(\"epoch %s validation accuracy: %f3 loss: %f3\" % (epoch, total_accuracy/n, total_loss.item()/n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 validation accuracy: 90.6550483 loss: 0.4014493\n",
      "epoch 1 validation accuracy: 79.4571313 loss: 1.8997593\n",
      "epoch 2 validation accuracy: 91.9771633 loss: 0.3372843\n",
      "epoch 3 validation accuracy: 89.4531253 loss: 0.5599303\n",
      "epoch 4 validation accuracy: 90.9955933 loss: 0.3977043\n"
     ]
    }
   ],
   "source": [
    "train_dl, valid_dl = get_data_loaders(train_ds, valid_ds, batch_size)\n",
    "model = create_model()\n",
    "optimizer = optimizers.SGD(model)\n",
    "loss_func = loss.cross_entropy()\n",
    "\n",
    "fit(5, model, train_dl, valid_dl, optimizer, loss_func)\n",
    "assert_valid_accuracy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Learner():\n",
    "    def __init__(self, model, optimizer, loss_func, data):\n",
    "        self.model,self.optimizer,self.loss_func,self.data = model,optimizer,loss_func,data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_simple_lin_model(data, lr=0.3, nh=50):\n",
    "    out_classes = data.train_ds.y.max().item()+1\n",
    "    in_ = data.train_ds.x.shape[1]\n",
    "    model = nn.Sequential(nn.Linear(in_,nh), nn.ReLU(), nn.Linear(nh,out_classes))\n",
    "    return model, optimizers.SGD(model, lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_bunch(train_ds,valid_ds, 64)\n",
    "learner = Learner(*get_simple_lin_model(data), loss.cross_entropy(), data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(epochs, learner):\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        # set model to train_mode\n",
    "        learner.model.train()\n",
    "        \n",
    "        for x_batch, y_batch in learner.data.train_dl:\n",
    "        \n",
    "            loss = learner.loss_func(learner.model(x_batch), y_batch)\n",
    "            \n",
    "            loss.backward()\n",
    "            learner.optimizer.step()\n",
    "            learner.optimizer.zero_grad()\n",
    "            \n",
    "        # set model to eval_mode\n",
    "        learner.model.eval()\n",
    "        with torch.no_grad():\n",
    "            total_accuracy, total_loss = 0., 0.\n",
    "            for x_valid_batch, y_valid_batch in learner.data.valid_dl:\n",
    "                valid_preds = learner.model(x_valid_batch)\n",
    "                total_loss+=learner.loss_func(valid_preds, y_valid_batch)\n",
    "                total_accuracy+=metrics.accuracy(valid_preds, y_valid_batch)\n",
    "                \n",
    "        n = len(valid_dl)        \n",
    "        print(\"epoch %s validation accuracy: %f3 loss: %f3\" % (epoch, total_accuracy/n, total_loss.item()/n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 validation accuracy: 94.1105773 loss: 0.2174523\n",
      "epoch 1 validation accuracy: 97.2956733 loss: 0.1177143\n",
      "epoch 2 validation accuracy: 97.3657853 loss: 0.1120413\n",
      "epoch 3 validation accuracy: 96.4643433 loss: 0.1554413\n",
      "epoch 4 validation accuracy: 97.2355773 loss: 0.1291563\n"
     ]
    }
   ],
   "source": [
    "fit(5, learner)\n",
    "assert_valid_accuracy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class CancelTrainException(Exception): pass\n",
    "class CancelEpochException(Exception): pass\n",
    "class CancelBatchException(Exception): pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Runner():\n",
    "    def __init__(self, cbs=None, cb_funcs=None):\n",
    "        cbs = listify(cbs)\n",
    "        for cbf in listify(cb_funcs):\n",
    "            cb = cbf()\n",
    "            setattr(self, cb.name, cb)\n",
    "            cbs.append(cb)\n",
    "        self.stop,self.cbs = False,[TrainEvalCallback()]+cbs\n",
    "\n",
    "    @property\n",
    "    def optimizer(self): return self.learn.optimizer\n",
    "    @property\n",
    "    def model(self):     return self.learn.model\n",
    "    @property\n",
    "    def loss_func(self): return self.learn.loss_func\n",
    "    @property\n",
    "    def data(self):      return self.learn.data\n",
    "    \n",
    "    def fit(self, epochs, learn):\n",
    "        self.epochs,self.learn,self.loss = epochs,learn,tensor(0.)\n",
    "\n",
    "        try:\n",
    "            for cb in self.cbs: cb.set_runner(self)\n",
    "            self('begin_fit')\n",
    "            for epoch in range(epochs):\n",
    "                self.epoch = epoch\n",
    "                if not self('begin_epoch'): self.train_with_batches(self.data.train_dl)\n",
    "                with torch.no_grad(): \n",
    "                    if not self('begin_validate'): self.train_with_batches(self.data.valid_dl)\n",
    "                self('after_epoch')\n",
    "        except CancelTrainException: self('after_cancel_train')\n",
    "        finally:\n",
    "            self('after_fit')\n",
    "            self.learn = None\n",
    "            \n",
    "    def train_with_batches(self, dl):\n",
    "        self.iters = len(dl)\n",
    "        try:\n",
    "            for xb,yb in dl: self.train_with_one_batch(xb, yb)\n",
    "        except CancelEpochException: self('after_cancel_epoch')\n",
    "\n",
    "    def train_with_one_batch(self, xb, yb):\n",
    "        try:\n",
    "            self.xb,self.yb = xb,yb\n",
    "            self('begin_batch')\n",
    "            self.pred = self.model(self.xb)\n",
    "            self('after_pred')\n",
    "            self.loss = self.loss_func(self.pred, self.yb)\n",
    "            self('after_loss')\n",
    "            \n",
    "            if not self.in_train: return\n",
    "            \n",
    "            self.loss.backward()\n",
    "            self('after_backward')\n",
    "            self.optimizer.step()\n",
    "            self('after_step')\n",
    "            self.optimizer.zero_grad()\n",
    "        except CancelBatchException: self('after_cancel_batch')\n",
    "        finally: self('after_batch')\n",
    "\n",
    "    def __call__(self, cb_name):\n",
    "        res = False\n",
    "        for cb in sorted(self.cbs, key=lambda x: x._order): res = cb(cb_name) or res\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: [0.2935611328125, 90.882]\n",
      "valid: [0.17310931396484375, 94.77]\n",
      "train: [0.139687216796875, 95.77]\n",
      "valid: [0.13471903076171876, 96.2]\n",
      "CPU times: user 12.2 s, sys: 421 ms, total: 12.7 s\n",
      "Wall time: 4.9 s\n"
     ]
    }
   ],
   "source": [
    "data = data_bunch(train_ds,valid_ds, 64)\n",
    "learner = Learner(*get_simple_lin_model(data), loss.cross_entropy(), data)\n",
    "\n",
    "stats = AvgStatsCallback([metrics.accuracy])\n",
    "run = Runner(cbs=stats)\n",
    "%time run.fit(2, learner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Lambda(nn.Module):\n",
    "    def __init__(self, func):\n",
    "        super().__init__()\n",
    "        self.func = func\n",
    "\n",
    "    def forward(self, x): return self.func(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted model_dev.ipynb to fastml/model/model.py\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of fastml.model.image.cnn failed: Traceback (most recent call last):\n",
      "  File \"/Users/kuptservol/miniconda2/envs/fastml/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 245, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/Users/kuptservol/miniconda2/envs/fastml/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 434, in superreload\n",
      "    module = reload(module)\n",
      "  File \"/Users/kuptservol/miniconda2/envs/fastml/lib/python3.7/imp.py\", line 314, in reload\n",
      "    return importlib.reload(module)\n",
      "  File \"/Users/kuptservol/miniconda2/envs/fastml/lib/python3.7/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 630, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 728, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"/Users/kuptservol/work/code/fastml/fastml/model/image/cnn.py\", line 5, in <module>\n",
      "    from fastml.model.callbacks import view_tfm\n",
      "ImportError: cannot import name 'view_tfm' from 'fastml.model.callbacks' (/Users/kuptservol/work/code/fastml/fastml/model/callbacks.py)\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "!python notebook2script.py model_dev.ipynb fastml/model/model.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
