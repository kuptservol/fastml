{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from fastml.core import *\n",
    "from fastml.data.datasets import *\n",
    "from fastml.model import loss as loss\n",
    "from fastml.model import metrics as metrics\n",
    "from fastml.model import optimizers\n",
    "from fastml.model.callbacks import *\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, n_in, nh, n_out):\n",
    "        super().__init__()\n",
    "        self.layers = [nn.Linear(n_in,nh), nn.ReLU(), nn.Linear(nh,n_out)]\n",
    "        self.loss = loss.mse\n",
    "        \n",
    "    def __call__(self, x, targ):\n",
    "        for layer in self.layers: x = layer(x)\n",
    "        return self.loss(x.squeeze(), targ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds,valid_ds = Datasets.MNIST()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50000, 784])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(784, 50, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, n_in, nh, n_out):\n",
    "        super().__init__()\n",
    "        self.l1 = nn.Linear(n_in, nh)\n",
    "        self.l2 = nn.Linear(nh, n_out)\n",
    "\n",
    "    def __call__(self, x): return self.l2(F.relu(self.l1(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name,l in model.named_children(): print(f\"{name}: {l}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-0.2254,  0.4871, -0.4744,  0.0137, -0.2635,  0.3699,  0.4965,  0.0540,\n",
       "          0.4427, -0.3002], grad_fn=<SelectBackward>), torch.Size([64, 10]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs=64 # batch size\n",
    "\n",
    "model = Model(784, 50, 10)\n",
    "xb, yb = train_ds[0:bs] # a mini-batch from x\n",
    "preds = model(xb)      # predictions\n",
    "\n",
    "preds[0], preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = metrics.accuracy(preds, yb[0:bs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## basic train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = train_ds.x, train_ds.y\n",
    "x_valid, y_valid = valid_ds.x, valid_ds.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.5\n",
    "epochs = 2\n",
    "batch_size=64\n",
    "loss_func = loss.cross_entropy()\n",
    "model = Model(784, 50, 10)\n",
    "\n",
    "def fit():\n",
    "    for epoch in range(epochs):\n",
    "        for batch in range(x_train.shape[0]//batch_size):\n",
    "            \n",
    "            b_from = batch*batch_size\n",
    "            b_to = b_from + batch_size\n",
    "            x_batch, y_batch = train_ds[b_from:b_to]\n",
    "            \n",
    "            loss = loss_func(model(x_batch), y_batch)\n",
    "            \n",
    "            loss.backward()\n",
    "            with torch.no_grad():\n",
    "                for p in model.parameters(): p -= lr * p.grad\n",
    "                model.zero_grad()\n",
    "            \n",
    "        accuracy = metrics.accuracy(model(x_train), y_train)\n",
    "        print(\"epoch %s accuracy is %f3\" % (epoch, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assert_train_accuracy():\n",
    "    assert metrics.accuracy(model(x_train), y_train) > 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 accuracy is 90.4500013\n",
      "epoch 1 accuracy is 92.9000023\n"
     ]
    }
   ],
   "source": [
    "fit()\n",
    "assert_train_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequentialModel(nn.Module):\n",
    "    def __init__(self, layers):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList(layers)\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        for l in self.layers: x = l(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 accuracy is 88.9259993\n",
      "epoch 1 accuracy is 89.8760023\n"
     ]
    }
   ],
   "source": [
    "layers = [nn.Linear(784,50), nn.ReLU(), nn.Linear(50,10)]\n",
    "model = SequentialModel(layers)\n",
    "\n",
    "fit()\n",
    "assert_train_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 accuracy is 91.6260003\n",
      "epoch 1 accuracy is 92.7339973\n"
     ]
    }
   ],
   "source": [
    "model = nn.Sequential(nn.Linear(784,50), nn.ReLU(), nn.Linear(50,10))\n",
    "\n",
    "fit()\n",
    "assert_train_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=784, out_features=50, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=50, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    return nn.Sequential(nn.Linear(784,50), nn.ReLU(), nn.Linear(50,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 accuracy is 88.6420013\n",
      "epoch 1 accuracy is 91.5080013\n"
     ]
    }
   ],
   "source": [
    "model = create_model()\n",
    "\n",
    "fit()\n",
    "assert_train_accuracy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## with optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model()\n",
    "optimizer = optimizers.SGD(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit():\n",
    "    for epoch in range(epochs):\n",
    "        for batch in range(x_train.shape[0]//batch_size):\n",
    "            \n",
    "            b_from = batch*batch_size\n",
    "            b_to = b_from + batch_size\n",
    "            x_batch, y_batch = train_ds[b_from:b_to]\n",
    "            \n",
    "            loss = loss_func(model(x_batch), y_batch)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "        accuracy = metrics.accuracy(model(x_train), y_train)\n",
    "        print(\"epoch %s accuracy is %f3\" % (epoch, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 accuracy is 91.1840023\n",
      "epoch 1 accuracy is 91.9460003\n"
     ]
    }
   ],
   "source": [
    "fit()\n",
    "assert_train_accuracy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## with data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl,_ = get_data_loaders(train_ds, valid_ds, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model()\n",
    "optimizer = optimizers.SGD(model)\n",
    "\n",
    "def fit():\n",
    "    for epoch in range(epochs):\n",
    "        for x_batch, y_batch in train_dl:\n",
    "            \n",
    "            loss = loss_func(model(x_batch), y_batch)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "        accuracy = metrics.accuracy(model(x_train), y_train)\n",
    "        print(\"epoch %s accuracy is %f3\" % (epoch, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 accuracy is 92.4279993\n",
      "epoch 1 accuracy is 89.7840023\n"
     ]
    }
   ],
   "source": [
    "fit()\n",
    "assert_train_accuracy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## with validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assert_valid_accuracy():\n",
    "    assert metrics.accuracy(model(x_valid), y_valid) > 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(epochs, model, train_dl, valid_dl, optimizer, loss_func):\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        # set model to train_mode\n",
    "        model.train()\n",
    "        \n",
    "        for x_batch, y_batch in train_dl:\n",
    "        \n",
    "            loss = loss_func(model(x_batch), y_batch)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "        # set model to eval_mode\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            total_accuracy, total_loss = 0., 0.\n",
    "            for x_valid_batch, y_valid_batch in valid_dl:\n",
    "                valid_preds = model(x_valid_batch)\n",
    "                total_loss+=loss_func(valid_preds, y_valid_batch)\n",
    "                total_accuracy+=metrics.accuracy(valid_preds, y_valid_batch)\n",
    "                \n",
    "        n = len(valid_dl)        \n",
    "        print(\"epoch %s validation accuracy: %f3 loss: %f3\" % (epoch, total_accuracy/n, total_loss.item()/n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 validation accuracy: 81.8910263 loss: 0.6780233\n",
      "epoch 1 validation accuracy: 92.4879813 loss: 0.3591723\n",
      "epoch 2 validation accuracy: 95.9635423 loss: 0.1665853\n",
      "epoch 3 validation accuracy: 96.2640223 loss: 0.1649593\n",
      "epoch 4 validation accuracy: 96.5344553 loss: 0.1715903\n"
     ]
    }
   ],
   "source": [
    "train_dl, valid_dl = get_data_loaders(train_ds, valid_ds, batch_size)\n",
    "model = create_model()\n",
    "optimizer = optimizers.SGD(model)\n",
    "loss_func = loss.cross_entropy()\n",
    "\n",
    "fit(5, model, train_dl, valid_dl, optimizer, loss_func)\n",
    "assert_valid_accuracy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Learner():\n",
    "    def __init__(self, model, optimizer, loss_func, data):\n",
    "        self.model,self.optimizer,self.loss_func,self.data = model,optimizer,loss_func,data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_simple_lin_model(data, lr=0.3, nh=50):\n",
    "    out_classes = data.train_ds.y.max().item()+1\n",
    "    in_ = data.train_ds.x.shape[1]\n",
    "    model = nn.Sequential(nn.Linear(in_,nh), nn.ReLU(), nn.Linear(nh,out_classes))\n",
    "    return model, optimizers.SGD(model, lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_bunch(train_ds,valid_ds, 64)\n",
    "learner = Learner(*get_simple_lin_model(data), loss.cross_entropy(), data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(epochs, learner):\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        # set model to train_mode\n",
    "        learner.model.train()\n",
    "        \n",
    "        for x_batch, y_batch in learner.data.train_dl:\n",
    "        \n",
    "            loss = learner.loss_func(learner.model(x_batch), y_batch)\n",
    "            \n",
    "            loss.backward()\n",
    "            learner.optimizer.step()\n",
    "            learner.optimizer.zero_grad()\n",
    "            \n",
    "        # set model to eval_mode\n",
    "        learner.model.eval()\n",
    "        with torch.no_grad():\n",
    "            total_accuracy, total_loss = 0., 0.\n",
    "            for x_valid_batch, y_valid_batch in learner.data.valid_dl:\n",
    "                valid_preds = learner.model(x_valid_batch)\n",
    "                total_loss+=learner.loss_func(valid_preds, y_valid_batch)\n",
    "                total_accuracy+=metrics.accuracy(valid_preds, y_valid_batch)\n",
    "                \n",
    "        n = len(valid_dl)        \n",
    "        print(\"epoch %s validation accuracy: %f3 loss: %f3\" % (epoch, total_accuracy/n, total_loss.item()/n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 validation accuracy: 96.7748403 loss: 0.1289533\n",
      "epoch 1 validation accuracy: 96.5645033 loss: 0.1389913\n",
      "epoch 2 validation accuracy: 97.1053693 loss: 0.1230163\n",
      "epoch 3 validation accuracy: 88.0709133 loss: 0.6151113\n",
      "epoch 4 validation accuracy: 97.4859783 loss: 0.1289313\n"
     ]
    }
   ],
   "source": [
    "fit(5, learner)\n",
    "assert_valid_accuracy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class CancelTrainException(Exception): pass\n",
    "class CancelEpochException(Exception): pass\n",
    "class CancelBatchException(Exception): pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Runner():\n",
    "    def __init__(self, cbs=None, cb_funcs=None):\n",
    "        cbs = listify(cbs)\n",
    "        for cbf in listify(cb_funcs):\n",
    "            cb = cbf()\n",
    "            setattr(self, cb.name, cb)\n",
    "            cbs.append(cb)\n",
    "        self.stop,self.cbs = False,[TrainEvalCallback()]+cbs\n",
    "\n",
    "    @property\n",
    "    def optimizer(self): return self.learn.optimizer\n",
    "    @property\n",
    "    def model(self):     return self.learn.model\n",
    "    @property\n",
    "    def loss_func(self): return self.learn.loss_func\n",
    "    @property\n",
    "    def data(self):      return self.learn.data\n",
    "    \n",
    "    def fit(self, epochs, learn):\n",
    "        self.epochs,self.learn,self.loss = epochs,learn,tensor(0.)\n",
    "\n",
    "        try:\n",
    "            for cb in self.cbs: cb.set_runner(self)\n",
    "            self('begin_fit')\n",
    "            for epoch in range(epochs):\n",
    "                self.epoch = epoch\n",
    "                if not self('begin_epoch'): self.train_with_batches(self.data.train_dl)\n",
    "                with torch.no_grad(): \n",
    "                    if not self('begin_validate'): self.train_with_batches(self.data.valid_dl)\n",
    "                self('after_epoch')\n",
    "        except CancelTrainException: self('after_cancel_train')\n",
    "        finally:\n",
    "            self('after_fit')\n",
    "            self.learn = None\n",
    "            \n",
    "    def train_with_batches(self, dl):\n",
    "        self.iters = len(dl)\n",
    "        try:\n",
    "            for xb,yb in dl: self.train_with_one_batch(xb, yb)\n",
    "        except CancelEpochException: self('after_cancel_epoch')\n",
    "\n",
    "    def train_with_one_batch(self, xb, yb):\n",
    "        try:\n",
    "            self.xb,self.yb = xb,yb\n",
    "            self('begin_batch')\n",
    "            self.pred = self.model(self.xb)\n",
    "            self('after_pred')\n",
    "            self.loss = self.loss_func(self.pred, self.yb)\n",
    "            self('after_loss')\n",
    "            \n",
    "            if not self.in_train: return\n",
    "            \n",
    "            self.loss.backward()\n",
    "            self('after_backward')\n",
    "            self.optimizer.step()\n",
    "            self('after_step')\n",
    "            self.optimizer.zero_grad()\n",
    "        except CancelBatchException: self('after_cancel_batch')\n",
    "        finally: self('after_batch')\n",
    "\n",
    "    def __call__(self, cb_name):\n",
    "        res = False\n",
    "        for cb in sorted(self.cbs, key=lambda x: x._order): res = cb(cb_name) or res\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: [0.27009966796875, 91.696]\n",
      "valid: [0.279593408203125, 91.34]\n",
      "train: [0.134194267578125, 96.002]\n",
      "valid: [0.53961279296875, 90.08]\n",
      "train: [0.104303935546875, 96.882]\n",
      "valid: [0.11928544921875, 96.74]\n",
      "train: [0.08923349609375, 97.234]\n",
      "valid: [0.13650467529296875, 96.36]\n",
      "train: [0.0741594140625, 97.696]\n",
      "valid: [0.2293269287109375, 94.62]\n"
     ]
    }
   ],
   "source": [
    "data = data_bunch(train_ds,valid_ds, 64)\n",
    "learner = Learner(*get_simple_lin_model(data), loss.cross_entropy(), data)\n",
    "\n",
    "stats = AvgStatsCallback([metrics.accuracy])\n",
    "run = Runner(cbs=stats)\n",
    "run.fit(5, learner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Lambda(nn.Module):\n",
    "    def __init__(self, func):\n",
    "        super().__init__()\n",
    "        self.func = func\n",
    "\n",
    "    def forward(self, x): return self.func(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted model_dev.ipynb to fastml/model/model.py\r\n"
     ]
    }
   ],
   "source": [
    "!python notebook2script.py model_dev.ipynb fastml/model/model.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
